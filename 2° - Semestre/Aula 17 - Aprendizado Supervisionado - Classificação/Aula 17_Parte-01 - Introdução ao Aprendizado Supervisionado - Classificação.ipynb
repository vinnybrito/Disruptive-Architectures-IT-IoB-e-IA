{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 17 - Introdução ao Aprendizado Supervisionado: Classificação - parte 1\n",
    "\n",
    "Nesta aula vamos estudar o uso de algoritmos de **Aprendizado de Máquina Supervisionado**. Focaremos nos algoritmos utilizados para **classificação**, que é a tarefa de predizer classes (rótulos categóricos) para conjuntos de dados (numéricos ou transformados em numéricos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro passo: carregar os dados e fazer Análise Exploratória\n",
    "\n",
    "Como já fizemos a Análise Exploratória com esses dados na outras aulas, iremos pular essa etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.DataFrame(data=iris.data, # Estamos dizendo que o dados do dataframe são o atributo data do objeto iris\n",
    "                     columns = iris.feature_names) # Já o nome das colunas do dataframe serão o atrib feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.hist(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.boxplot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo passo: separar os dados\n",
    "\n",
    "Precisamos ter claro em nossas mentes quais são os atributos (colunas) preditivas, isto é, aquelas que usaremos para predizer um atributo alvo (coluna alvo). No nosso caso os **atributos preditivos são Comprimento de sépalas e pétalas**, e o **atributo alvo é a tipo da flor** que será predita.\n",
    "\n",
    "Quando se trabalhar com Aprendizado de Máquina Supervisionado, além disso precisamos separar nossos dados em dois conjuntos: um **conjunto de treinamento** e um **conjunto de teste**. Fazemos isso para evitar overfitting do algoritmo.\n",
    "\n",
    "Inicialmente vamos integrar o atributo alvo, entender e depois separar em atributos e alvos.\n",
    "\n",
    "Existem várias estratégias para se separar dados. Vamos aplicar as principais:\n",
    "\n",
    "(a) Escolher o tamanho dos conjuntos - 80% para treinamento e 20% para teste;\n",
    "\n",
    "(b) Selecionar aleatoriamente os dados que irão compor o conjunto de treinamento e teste (usando um seed para garantir reprodutibilidade);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos adicionar a coluna Target - que é o tipo de cada flor\n",
    "dados['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos separar as FEATURES e LABELS:\n",
    "X = dados[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].values\n",
    "y = dados['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (z, w) in zip(X, y):\n",
    "    print(f'Feature: {z}, Label: {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                   test_size= 0.2,\n",
    "                                                   random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training set size: {X_train.shape[0]} samples \\ntest set size: {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terceiro passo: transformar os dados \n",
    "\n",
    "Dependendo do algoritmo de Aprendizado de Máquina que usamos precisamos modificar os dados para que eles se adequem as premissas do algoritmo. \n",
    "\n",
    "Existem duas transformações de escalonamento muito utilizadas:\n",
    "\n",
    "1) **Nomalização** (Normalization) - Também conhecido como escalonamento Min-Max no qual o range de valores da coluna irá fica de 0 (min) até 1 (max);\n",
    "\n",
    "2) **Padronização** (Standardization) - Modifica a distribuição para que a média seja igual a zero e desvio padrão igual a 1 (o método subtrai a média de todas as entradas e dividide pelo desvio padrão); \n",
    "\n",
    "Quando escolher uma ou outra? Depende dos seus dados, seu problema e o algoritmo que você quer usar. Em alguns casos, escalonar ou não os dados não irá mudar a solução do problema! Ao longo do cursos iremos estudar alguns casos...\n",
    "\n",
    "**IMPORTANTE**: independentmente do transformador escolhido, ele deve ser fitado apenas sobre os dados de treinamento. Isto é, o treinamento do escalonador deve receber apenas os dados de treinamento x_train. Após o treinamento do escalonador, ele deverá ser usado para transformar os dados x_test também. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarto passo: treinar o algoritmo \n",
    "\n",
    "Vamos usar o conjunto de treinamento para treinar o algoritmo escolhido.\n",
    "\n",
    "Existem vários algoritmos possíveis. Cada algoritmo tem seus **hiperparâmetros** (parâmetros que devem ser escolhidos para melhorar a performance do algoritmo). Para entender os hiperparâmetros de cada algoritmo é necessário entender a fundo como aquele algoritmo funciona.\n",
    "\n",
    "Aqui vamos usar um dos algoritmos mais simples existentes, o **KNN - K Nearest Neighboors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "knn = KNeighborsClassifier(K)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Como sabemos se o algoritmo está bom?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quinto passo: testar e avaliar \n",
    "\n",
    "Usando agora o conjunto de teste, iremos testar o classificador criado e treinando no passo anterior.\n",
    "\n",
    "Uma vez que realizamos um teste, precisamos avaliar o desempenho do nosso método. Diferentes hiperparâmetros e diferentes algoritmos podem ter um desempenho diferente. Apesar de sempre buscarmos o melhor desempenho, devemos levar em consideração outros aspectos para decidir o que é um desempenho aceitável. A primeira coisa a definir são as **métricas de desempenho** que podem ser comparadas entre diferentes algoritmos. \n",
    "\n",
    "Existem várias métricas para se medir o desempenho de um classificador: métricas de performance, métricas de tempo consumido, métricas de memória consumida, etc. Vamos focar em uma métrica de performance muito utilizada no dia a dia de trabalho: a **Matriz de Confusão** e seus índices (**Acurácia, Precisão, Recall e F1-score**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicoes = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando uma figura com a matriz de confusao\n",
    "figure = plt.figure(figsize=(15, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao, display_labels=['Setosa', 'Versicolor', 'Virginica'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true = y_test, y_pred = y_predicoes,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
